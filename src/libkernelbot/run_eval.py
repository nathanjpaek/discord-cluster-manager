import dataclasses
import datetime
import functools
import json
import os
import shlex
import shutil
import subprocess
import tempfile
import time
from pathlib import Path
from types import NoneType
from typing import Optional, Protocol, Union

from libkernelbot.consts import CUDA_FLAGS, ExitCode, Timeout


@dataclasses.dataclass
class ProfileResult:
    # fmt: off
    profiler: str      # The profiler used to gather this data
    # Public download URL of all files created by the profiler
    # This may also be configured later
    download_url: Optional[str]
    #fmt: on


@dataclasses.dataclass
class CompileResult:
    # fmt: off
    nvcc_found: bool    # did we find nvcc?
    nvcc_version: str   # the result of nvcc --version
    success: bool       # did it compile successfully
    command: str        # the command that was run to compile the code
    stdout: str         # standard output produced by the compiler
    stderr: str         # standard error produced by the compiler
    exit_code: int      # exit code produced by the compiler
    # fmt: on


@dataclasses.dataclass
class RunResult:
    # fmt: off
    success: bool       # did the compiled executable run successfully
    passed: bool        # did it pass all tests
    command: str        # the command that was run to compile the code
    stdout: str         # standard output produced by the compiler
    stderr: str         # standard error produced by the compiler
    exit_code: int      # exit code produced by the compiler
    duration: float     # execution time (NOT kernel duration)
    result: dict        # dictionary with the results generated by the tester
    # fmt: on


@dataclasses.dataclass
class SystemInfo:
    # fmt: off
    gpu: str = ''           # Model name of the GPU
    device_count: int = 1   # Number of GPUs
    cpu: str = ''           # Model name of the CPU
    runtime: str = ''       # Whether CUDA or ROCm
    platform: str = ''      # Platform string of the machine
    torch: str = ''         # Torch version
    # fmt: on


@dataclasses.dataclass
class EvalResult:
    # fmt: off
    start: datetime.datetime            # when did this run start (excluding container setup time)
    end: datetime.datetime              # and when did it finish
    compilation: CompileResult | None   # results of compilation
    run: RunResult | None               # result of actually running the executable/script
    profile: ProfileResult | None       # result of profiling the executable
    # fmt: on


@dataclasses.dataclass
class FullResult:
    # fmt: off
    success: bool                  # did the runner (github/modal) execute successfully
    error: str                     # if not success, an error message
    system: SystemInfo             # specs of the system this was run on
    # results of running. There can be multiple runs in one submission, using separate
    # 'test' and 'benchmark' keys, for example
    runs: dict[str, EvalResult] = dataclasses.field(default_factory=dict)
    # fmt: on


def _make_cmd(args: list[str]):
    return " ".join(map(shlex.quote, args))


def _limit_length(text: Union[NoneType, str, bytes], max_len: int = 16384):
    if text is None:
        return ""
    if isinstance(text, bytes):
        text = text.decode("utf-8")
    lines = text.split("\n")
    size = 0
    for i, line in enumerate(lines):
        size += len(line) + 1
        if size + 100 > max_len:
            lines = lines[:i] + [f"[...] {len(lines) - i} lines omitted"]
            return "\n".join(lines)
    return text


def _create_files(files: Optional[dict[str, str]]):
    """
    Create text files
    Args:
        files: A dictionary mapping file names to their contents.
    Raises:
        AssertionError, if the file is not within the current working directory.
    """
    if files is None:
        return

    for name, content in files.items():
        assert Path(name).resolve().is_relative_to(Path.cwd())
        Path(name).write_text(content)


def _prepend_env_path(var_name: str, entries: list[str]) -> None:
    existing = os.environ.get(var_name, "")
    parts = [p for p in existing.split(os.pathsep) if p]
    updated = False
    for entry in entries:
        if not entry:
            continue
        if entry not in parts:
            parts.insert(0, entry)
            updated = True
    if updated:
        os.environ[var_name] = os.pathsep.join(parts)


def _ensure_cuda_paths() -> None:
    roots = []
    for env_var in ("CUDA_HOME", "CUDA_PATH"):
        root = os.environ.get(env_var)
        if root:
            roots.append(Path(root))

    roots.extend(
        [
            Path("/usr/local/cuda-12.2"),
            Path("/usr/local/cuda"),
        ]
    )

    bin_entries: list[str] = []
    lib_entries: list[str] = []

    for root in roots:
        try:
            resolved = root.resolve()
        except FileNotFoundError:
            continue
        bin_dir = resolved / "bin"
        lib_dir = resolved / "lib64"
        if bin_dir.is_dir():
            bin_entries.append(str(bin_dir))
        if lib_dir.is_dir():
            lib_entries.append(str(lib_dir))

    if bin_entries:
        _prepend_env_path("PATH", bin_entries)
    if lib_entries:
        _prepend_env_path("LD_LIBRARY_PATH", lib_entries)


def compile_cuda_script(  # # noqa: C901
    files: list[str],
    arch: Optional[int] = None,
    include_dirs: Optional[list[str]] = None,
    defines: Optional[dict[str, str]] = None,
    libraries: Optional[list[str]] = None,
    flags: Optional[list[str]] = None,
    verbose: bool = False,
) -> CompileResult:
    """
    Compiles a set of cuda files with nvcc.

    Args:
        files: List of files to compile.
        arch: Architecture to compile for. If None, uses `native`
        include_dirs: additional include directories to supply to nvcc
        defines: Additional defines for the preprocessor
        libraries: Additional libraries to link to
        flags: Other compiler flags
        verbose: whether to print progress or be silent
    Returns:
        A `CompileResult` that summarizes the compilation process.

    """
    if flags is None:
        flags = CUDA_FLAGS

    if include_dirs is not None:
        flags += [f"-I{d}" for d in include_dirs]
        # validate include directories
        for directory in include_dirs:
            if not Path(directory).exists():
                raise FileNotFoundError(f"Directory `{directory}` does not exist")
            elif not Path(directory).is_dir():
                raise NotADirectoryError(f"`{directory}` is not a directory")

    if libraries is not None:
        flags += [f"-l{lib}" for lib in libraries]

    if defines is not None:
        for name, value in defines.items():
            # restrict macro names to valid identifiers
            if not name.isidentifier():
                raise ValueError(f"Define key `{name}` contains invalid character")

            if value is not None:
                flags.append(f"-D{name}={value}")
            else:
                flags.append(f"-D{name}")

    for flag in flags:
        if not flag.startswith("-"):
            raise ValueError(f"Flag `{flag}` should start with a dash.")

    if verbose:
        print_ = print
    else:
        print_ = lambda *args, **kwargs: None  # noqa

    # Check CUDA is available and installed correctly
    print_("[CUDA Env Check]")
    # temp hack on L40S
    _ensure_cuda_paths()
    try:
        # these check cuda compiler is also available
        nvcc = subprocess.check_output(["which", "nvcc"], encoding="utf-8").strip()
        nvcc_version = subprocess.check_output(["nvcc", "--version"], encoding="utf-8")
        print(f"[CUDA Env Check] NVCC found: {nvcc} {nvcc_version}")
    except subprocess.CalledProcessError as e:
        return CompileResult(
            nvcc_found=False,
            success=False,
            nvcc_version="",
            command=_make_cmd(e.cmd),
            stdout=_limit_length(e.stdout),
            stderr=_limit_length(e.stderr),
            exit_code=e.returncode,
        )

    if arch is None:
        ARCH = "-arch=native"
    else:
        ARCH = f"-gencode=arch=compute_{arch},code=sm_{arch}"

    command = [nvcc] + flags + files + [ARCH, "-o", "eval.out"]

    print_("[Compiling]")
    try:
        compile_process = subprocess.run(
            command, capture_output=True, text=True, check=True, timeout=Timeout.COMPILE
        )
    except subprocess.CalledProcessError as e:
        return CompileResult(
            nvcc_found=True,
            success=False,
            nvcc_version=nvcc_version,
            command=_make_cmd(e.cmd),
            stdout=_limit_length(e.stdout),
            stderr=_limit_length(e.stderr),
            exit_code=e.returncode,
        )

    return CompileResult(
        nvcc_found=True,
        success=True,
        nvcc_version=nvcc_version,
        command=_make_cmd(compile_process.args),
        stdout=_limit_length(compile_process.stdout),
        stderr=_limit_length(compile_process.stderr),
        exit_code=compile_process.returncode,
    )


def run_program(
    args: list[str],
    seed: Optional[int],
    timeout: int,
    multi_gpu: bool = False,
    extra_env: Optional[dict[str, str]] = None,
) -> RunResult:
    print("[Running]")
    # set up a pipe so the tester can communicate its verdict with us
    env = os.environ.copy()
    if extra_env is not None:
        env.update(extra_env)

    pipe_read, pipe_write = os.pipe()
    env["POPCORN_FD"] = str(pipe_write)
    if seed is not None:
        env["POPCORN_SEED"] = str(seed)

    if multi_gpu:
        import torch

        env["POPCORN_GPUS"] = str(torch.cuda.device_count())

    execution_start_time = time.perf_counter()
    try:
        run_process = subprocess.run(
            args,
            capture_output=True,
            text=True,
            check=False,
            env=env,
            pass_fds=[pipe_write],
            timeout=timeout,
        )
    except subprocess.TimeoutExpired as e:
        return RunResult(
            success=False,
            passed=False,
            command=_make_cmd(e.cmd),
            stdout=_limit_length(e.stdout),
            stderr=_limit_length(e.stderr),
            exit_code=ExitCode.TIMEOUT_EXPIRED,
            duration=timeout,
            result={},
        )
    execution_end_time = time.perf_counter()

    # terminate output writing
    os.close(pipe_write)
    # and fetch pipe's content
    result = os.fdopen(pipe_read, "r").read()

    result_dict = {}
    for line in result.splitlines():
        key, _, value = line.partition(":")
        if key != "" or value != "":
            result_dict[key.strip()] = value.strip()

    return RunResult(
        success=(
            run_process.returncode == ExitCode.SUCCESS
            or run_process.returncode == ExitCode.VALIDATE_FAIL
        ),
        passed=result_dict.get("check", None) == "pass",
        command=_make_cmd(run_process.args),
        stdout=_limit_length(run_process.stdout),
        stderr=_limit_length(run_process.stderr),
        exit_code=run_process.returncode,
        duration=execution_end_time - execution_start_time,
        result=result_dict,
    )


def profile_program(
    system: SystemInfo,
    call: list[str],
    seed: Optional[int],
    timeout: int,
    multi_gpu: bool,
    submission_source: Optional[str] = None,
    arch: Optional[int] = None,
    test_file: Optional[str] = None,
    **extra_kwargs,
) -> tuple[RunResult, Optional[ProfileResult]]:
    # The runner-specific configuration should implement logic
    # to fetch the data in this directory and return it as
    # ProfileResult.download_url.
    # Insert an extra nested nested path here so that the resulting zip has all files
    # in the profile_data/ directory rather than directly in the root.
    output_dir = Path(".") / "profile_data" / "profile_data"
    output_dir.mkdir(parents=True, exist_ok=True)

    if system.runtime == "ROCm":
        # Wrap program in rocprof
        call = [
            "rocprofv3",
            "--log-level",
            "fatal",
            "--hip-trace",
            "--kernel-trace",
            "--rccl-trace",
            "--marker-trace",
            "--hip-trace",
            "--memory-copy-trace",
            # New? Doesn't work in the runner
            # "--memory-allocation-trace",
            "--scratch-memory-trace",
            # The HSA trace output is very large, so skip it for now
            # "--hsa-trace",
            "--output-format",
            "pftrace",
            "csv",
            "-d",
            str(output_dir),
            # Just store the files as %pid%_tracename.ext instead of putting them in an
            # additional directory named after the hostname.
            "-o",
            # Insert an extra path here so that the resulting zip has all files
            # in the profile_data/ directory rather than the root.
            "%pid%",
            "--",
        ] + call

        run_result = run_program(call, seed=seed, timeout=timeout, multi_gpu=multi_gpu, extra_env={
            "GPU_DUMP_CODE_OBJECT": "1",
        })

        profile_result = None

        if run_result.success:
            # Post-process trace data.
            # rocPROF generates one trace for every process, but its more useful to
            # have all traces be in the same file. Fortunately we can do that by
            # concatenating.
            traces = list(output_dir.glob("*.pftrace"))
            with (output_dir / "combined.pftrace").open("wb") as combined:
                for trace_path in traces:
                    with trace_path.open("rb") as trace:
                        shutil.copyfileobj(trace, combined)

                    # After we've created the combined trace, there is no point in
                    # keeping the individual traces around.
                    trace_path.unlink()

            # Also move the code objects to the profiling output directory.
            for code_obj in list(Path.cwd().glob("_code_object*.o")):
                code_obj.rename(output_dir / code_obj.name)

            profile_result = ProfileResult(
                profiler='rocPROF',
                download_url=None,
            )

        return run_result, profile_result
    elif system.runtime == "CUDA":
        # NCU profiling for CUDA
        ncu_output_dir = output_dir / "ncu_output"
        ncu_output_dir.mkdir(parents=True, exist_ok=True)
        
        print("[NCU Profiling] Running NCU with 6 metric sections...")
        
        # Try to use standalone binary if submission has main()
        use_standalone = False
        if submission_source and ("int main(" in submission_source or "void main(" in submission_source):
            print("[NCU Profiling] Detected standalone submission with main()")
            if _compile_standalone_for_profiling(submission_source, arch=arch):
                use_standalone = True
                call = ["./submission_standalone"]  # No arguments needed
                print("[NCU Profiling] Will profile standalone binary (no test harness)")
            else:
                print("[NCU Profiling] Falling back to eval harness")
        
        if not use_standalone:
            print("[NCU Profiling] Using eval harness approach")
        
        # Run NCU with 6 different metric sections
        sections = [
            ("SpeedOfLight", "speed_of_light.csv"),
            ("MemoryWorkloadAnalysis", "memory_analysis.csv"),
            ("ComputeWorkloadAnalysis", "compute_analysis.csv"),
            ("Occupancy", "occupancy.csv"),
            ("SchedulerStats", "scheduler_stats.csv"),
            ("WarpStateStats", "warp_stats.csv"),
        ]
        
        # Check if NCU is available
        try:
            ncu_check = subprocess.run(["ncu", "--version"], capture_output=True, text=True, timeout=5)
            print(f"[NCU Profiling] NCU version: {ncu_check.stdout.strip()}")
        except Exception as e:
            print(f"[NCU Profiling] Warning: NCU not found or not accessible: {e}")
        
        # Set up environment (only needed if using eval harness)
        env = os.environ.copy()
        if not use_standalone:
            pipe_read, pipe_write = os.pipe()
            env["POPCORN_FD"] = str(pipe_write)
            if seed is not None:
                env["POPCORN_SEED"] = str(seed)
            if multi_gpu:
                import torch
                env["POPCORN_GPUS"] = str(torch.cuda.device_count())
        
        ncu_success = True
        for section_name, csv_file in sections:
            try:
                print(f"[NCU Profiling] Running section: {section_name}")
                # Simple NCU invocation matching working shell script approach
                ncu_cmd = [
                    "ncu",
                    "--csv",
                    "--section", section_name
                ] + call
                print(f"[NCU Profiling] Command: {' '.join(ncu_cmd)}")
                
                # Run NCU with or without environment setup depending on standalone vs harness
                if use_standalone:
                    result = subprocess.run(
                        ncu_cmd,
                        capture_output=True,
                        text=True,
                        timeout=timeout,
                        check=False,
                    )
                else:
                    result = subprocess.run(
                        ncu_cmd,
                        capture_output=True,
                        text=True,
                        timeout=timeout,
                        check=False,
                        env=env,
                        pass_fds=[pipe_write],
                    )
                
                print(f"[NCU Profiling] Return code: {result.returncode}")
                print(f"[NCU Profiling] Stdout length: {len(result.stdout)} bytes")
                print(f"[NCU Profiling] Stderr length: {len(result.stderr)} bytes")
                
                # Write CSV output to file
                csv_path = ncu_output_dir / csv_file
                with open(csv_path, 'w') as f:
                    f.write(result.stdout)
                print(f"[NCU Profiling] Wrote {csv_path}")
                
                if result.returncode != 0:
                    print(f"[NCU Profiling] Warning: NCU section {section_name} returned code {result.returncode}")
                    print(f"[NCU Profiling] stderr: {result.stderr[:1000]}")
                    ncu_success = False
                elif len(result.stdout) < 100:
                    print(f"[NCU Profiling] Warning: NCU output seems too small for {section_name}")
                    print(f"[NCU Profiling] stdout: {result.stdout[:500]}")
                    print(f"[NCU Profiling] stderr: {result.stderr[:500]}")
                    
            except subprocess.TimeoutExpired:
                print(f"[NCU Profiling] Warning: NCU section {section_name} timed out")
                ncu_success = False
            except Exception as e:
                print(f"[NCU Profiling] Error running NCU section {section_name}: {e}")
                ncu_success = False
        
        # Clean up pipe (only if using eval harness)
        if not use_standalone:
            os.close(pipe_write)
            os.close(pipe_read)
        
        # Parse NCU results
        profile_result = None
        if ncu_success:
            try:
                from libkernelbot.ncu_parser import NCUParser
                
                parser = NCUParser(str(ncu_output_dir))
                parser.parse_all()
                
                # Save parsed JSON
                parser.to_json(str(ncu_output_dir / "parsed_metrics.json"))
                
                # Generate LLM prompt with kernel source
                llm_prompt = parser.to_llm_prompt(submission_source)
                with open(ncu_output_dir / "llm_prompt.txt", 'w') as f:
                    f.write(llm_prompt)
                print(f"[NCU Parser] LLM prompt saved to: {ncu_output_dir / 'llm_prompt.txt'}")
                
                profile_result = ProfileResult(
                    profiler='NCU',
                    download_url=None,
                )
            except Exception as e:
                print(f"[NCU Profiling] Error parsing NCU results: {e}")
        
        # Run the actual program to get execution results
        if use_standalone:
            # For standalone, just run it directly
            print("[Running standalone binary for test results]")
            run_result = run_program(["./submission_standalone"], seed=None, timeout=timeout, multi_gpu=multi_gpu)
        else:
            # For harness approach, run eval.out normally
            print("[Running eval harness for test results]")
            run_result = run_program(call, seed=seed, timeout=timeout, multi_gpu=multi_gpu)
        
        return run_result, profile_result
    else:
        # Fallback for other runtimes
        return run_program(call, seed=seed, timeout=timeout, multi_gpu=multi_gpu), None

def run_single_evaluation(
    system: SystemInfo,
    call: list[str],
    mode: str,
    *,
    multi_gpu: bool = False,
    tests: Optional[str] = None,
    benchmarks: Optional[str] = None,
    test_timeout: int = Timeout.TEST,
    benchmark_timeout: int = Timeout.BENCHMARK,
    ranked_timeout: int = Timeout.RANKED,
    ranking_by: str = "last",
    seed: Optional[int] = None,
    **extra_kwargs,
) -> tuple[RunResult, Optional[ProfileResult]]:
    """
    A single runner run, either in the context of test files, or in the
    context of benchmark files.
    """
    with tempfile.NamedTemporaryFile("w") as cases:
        if mode == "test":
            timeout = test_timeout
            cases.write(tests)
        elif mode == "profile":
            # Profile mode uses test cases, not benchmarks
            timeout = test_timeout
            cases.write(tests)
        elif mode in ["benchmark", "leaderboard"]:
            timeout = ranked_timeout if mode == "leaderboard" else benchmark_timeout
            if ranking_by == "last":
                cases.write(benchmarks.splitlines(keepends=True)[-1])
            else:
                cases.write(benchmarks)
        else:
            raise ValueError(f"Invalid mode {mode}")

        cases.flush()

        # For profile mode, we pass "test" to the executable but wrap it with profiling
        exec_mode = "test" if mode == "profile" else mode
        
        # Only add arguments if we have a call (not standalone profile mode)
        if call:
            call += [exec_mode, cases.name]

        if mode == "profile":
            # Pass the test cases file path for standalone profiling
            return profile_program(
                system, call, seed=seed, timeout=timeout, multi_gpu=multi_gpu,
                test_file=cases.name, **extra_kwargs
            )

        return run_program(call, seed=seed, timeout=timeout, multi_gpu=multi_gpu), None


def make_system_info() -> SystemInfo: # noqa: C901
    info = SystemInfo()
    try:
        import torch

        info.torch = torch.torch_version.internal_version
        # Note: cuda.is_available() also covers HiP
        # https://pytorch.org/docs/stable/notes/hip.html
        if torch.cuda.is_available():
            info.gpu = torch.cuda.get_device_name()
            info.device_count = torch.cuda.device_count()
            if torch.version.hip is not None:
                info.runtime = "ROCm"
            elif torch.version.cuda is not None:
                info.runtime = "CUDA"
    except ImportError:
        # get GPU info manually
        try:
            info.gpu = subprocess.check_output(
                ["nvidia-smi", "--query-gpu=name", "--format=csv,noheader"], encoding="utf-8"
            )
            info.device_count = info.gpu.count('\n')
            info.runtime = "CUDA"
        except subprocess.CalledProcessError:
            # try again for HIP
            try:
                rocm_info = json.loads(subprocess.check_output(
                    ["rocm-smi", "--showproductname", "--json"], encoding="utf-8"
                ))
                if len(rocm_info) > 0:
                    info.gpu = next(rocm_info.__iter__())["Card Series"]

                info.device_count = len(rocm_info)
                info.runtime = "ROCm"
            except subprocess.CalledProcessError:
                # OK, no GPU info available
                pass

    try:
        cpu_info_str = Path("/proc/cpuinfo").read_text()
        cpu_info_dict = {}
        for line in cpu_info_str.splitlines():
            key, _, val = line.partition(":")
            cpu_info_dict[key.strip()] = val.strip()
        info.cpu = cpu_info_dict.get("model name", "")
        # on modal, we don't get to know the exact CPU model
        # make due with the vendor in that case
        if info.cpu == "unknown":
            # ¯\_(ツ)_/¯
            info.cpu = cpu_info_dict.get("vendor_id", "")

    except PermissionError:
        # nothing we can do here; we're not getting CPU info
        pass
    import platform

    info.platform = platform.platform()

    return info


def _compile_standalone_for_profiling(
    submission_source: str,
    arch: Optional[int] = None,
) -> bool:
    """Compile submission as standalone binary for NCU profiling.
    Returns True if successful."""
    print("[Profiling] Compiling standalone binary for NCU...")
    
    # Write standalone submission
    Path("submission_standalone.cu").write_text(submission_source)
    
    # Compile standalone
    nvcc_cmd = ["nvcc", "-O3"]
    if arch is None:
        nvcc_cmd.append("-arch=native")
    else:
        nvcc_cmd.append(f"-gencode=arch=compute_{arch},code=sm_{arch}")
    nvcc_cmd.extend(["-o", "submission_standalone", "submission_standalone.cu"])
    
    try:
        result = subprocess.run(nvcc_cmd, capture_output=True, text=True, timeout=180, check=True)
        print("[Profiling] Standalone compilation successful")
        return True
    except Exception as e:
        print(f"[Profiling] Standalone compilation failed: {e}")
        return False


def run_cuda_script(  # # noqa: C901
    system: SystemInfo,
    sources: dict[str, str],
    headers: Optional[dict[str, str]] = None,
    arch: Optional[int] = None,
    defines: Optional[dict[str, str]] = None,
    include_dirs: Optional[list[str]] = None,
    libraries: Optional[list[str]] = None,
    flags: Optional[list[str]] = None,
    **kwargs,
) -> EvalResult:
    """
    Executes the provided CUDA kernel in an isolated environment

    Args:
        sources: The source files to compile. Mapping file name to content.
        headers: Additional header files to create for the compile run.
            Mapping of file name to file contents. These files will _not_ be added to the
            compile command.
        arch: The arch code for the compute/sm versions. If None, native arch is used.
        include_dirs: Additional include directories, e.g., for thunderkittens/cutlass etc
        defines: Preprocessor defines
        libraries: Additional libraries to link to
        flags: Additional flags to give to the compiler
        seed: Random seed to initialize the RNG for testing

    Returns:
        tuple[CompileResult, RunResult]: CUDA compile/eval result information
    """
    start = datetime.datetime.now()
    
    # Save submission source before cleanup (needed for NCU profiling)
    submission_source = sources.get("submission.cu", "")
    
    # Check if this is profile mode with a standalone kernel
    mode = kwargs.get("mode", "test")
    is_standalone_profile = (
        mode == "profile" and 
        submission_source and 
        ("int main(" in submission_source or "void main(" in submission_source)
    )
    
    if is_standalone_profile:
        print("[Profile Mode] Detected standalone kernel - skipping eval harness compilation")
        # For standalone profiling, we'll compile in profile_program instead
        # Create a dummy successful compile result
        compile_result = CompileResult(
            nvcc_found=True,
            nvcc_version="",
            success=True,
            command="(standalone profiling mode - compiled separately)",
            stdout="",
            stderr="",
            exit_code=0,
        )
    else:
        try:
            # Write submission files to directory
            _create_files(sources)
            _create_files(headers)

            compile_result = compile_cuda_script(
                files=list(sources.keys()),
                arch=arch,
                include_dirs=include_dirs,
                defines=defines,
                libraries=libraries,
                flags=flags,
                verbose=True,
            )

            if not compile_result.success:
                return EvalResult(
                    start=start,
                    end=datetime.datetime.now(),
                    compilation=compile_result,
                    run=None,
                    profile=None,
                )

        # cleaning up all source files _before_ we let the user code run, just in
        # case there's something in there that the user isn't supposed to snoop
        finally:
            tmp_files = list(sources.keys()) + list((headers or {}).keys())
            for f in tmp_files:
                if os.path.exists(f):
                    os.remove(f)

    # Pass submission source and arch to enable standalone profiling
    kwargs_with_extras = {**kwargs, "submission_source": submission_source, "arch": arch}
    
    if is_standalone_profile:
        # For standalone profile, we don't use eval.out
        run_result, profile_result = run_single_evaluation(system, [], **kwargs_with_extras)
    else:
        run_result, profile_result = run_single_evaluation(system, ["./eval.out"], **kwargs_with_extras)
    
    return EvalResult(
        start=start,
        end=datetime.datetime.now(),
        compilation=compile_result,
        run=run_result,
        profile=profile_result,
    )


def run_pytorch_script(  # noqa: C901
    system: SystemInfo,
    sources: dict[str, str],
    main: str,
    **kwargs,
) -> EvalResult:
    """
    Executes the provided PyTorch GPU kernel in an isolated environment

    Args:
        sources: Files to generate
        main: Which file to run. Must be one of the keys in sources.
        seed: Random seed to initialize the RNG for testing

    Returns:
        RunResult
    """
    start = datetime.datetime.now()
    try:
        assert main in sources.keys()

        # Write submission files to directory
        _create_files(sources)

        # "compile" step: execute the script once. Will populate
        # `load_inline`'s compile cache, so the actual runs will be faster.
        try:
            compile_run = run_program(["python", "submission.py"], seed=1, timeout=Timeout.COMPILE)
            if "-DTORCH_EXTENSION_NAME" in compile_run.stdout:
                comp = CompileResult(
                    nvcc_found=True,
                    nvcc_version="",
                    success=True,
                    command=compile_run.command,
                    stdout=compile_run.stdout,
                    stderr=compile_run.stderr,
                    exit_code=compile_run.exit_code,
                )
            else:
                comp = None
        except subprocess.CalledProcessError as e:
            # This step is purely optional, so we just go on
            # if it fails
            comp = CompileResult(
                nvcc_found=False,
                nvcc_version="",
                success=False,
                command="python submission.py",
                stdout=e.stdout,
                stderr=e.stderr,
                exit_code=e.returncode,
            )

        run, profile = run_single_evaluation(system, ["python", main], **kwargs)

        return EvalResult(
            start=start,
            end=datetime.datetime.now(),
            compilation=comp,
            run=run,
            profile=profile,
        )
    finally:
        for f in sources.keys():
            if os.path.exists(f):
                os.remove(f)


class _EvalRunner(Protocol):
    def __call__(self, mode: str) -> EvalResult: ...


def run_evaluation(
    call: _EvalRunner,
    mode: str,
) -> dict[str, EvalResult]:
    """
    Given a "runner" function `call`, interprets the mode
    and calls the runner with the right arguments.
    Simple modes (test, benchmark, profile) just
    invoke the runner once, but private/leaderboard
    require multiple runner calls.
    """
    results: dict[str, EvalResult] = {}
    if mode in ["test", "benchmark", "profile"]:
        results[mode] = call(mode=mode)
    elif mode in ["private", "leaderboard"]:
        # first, run the tests
        results["test"] = call(mode="test")

        if not results["test"].run or not results["test"].run.passed:
            return results

        results["benchmark"] = call(mode="benchmark")

        if not results["benchmark"].run or not results["benchmark"].run.passed:
            return results

        # if they pass, run the leaderboard validation
        results["leaderboard"] = call(mode="leaderboard")
    else:
        raise AssertionError("Invalid mode")

    return results


def build_test_string(tests: list[dict]):
    as_str = ""
    for test in tests:
        kvs = []
        for k, v in test.items():
            kvs.append(f"{k}: {v}")
        as_str += "; ".join(kvs) + "\n"
    return as_str


def run_config(config: dict):
    system = make_system_info()
    common_args = {
        "system": system,
        "tests": build_test_string(config.get("tests", [])),
        "benchmarks": build_test_string(config.get("benchmarks", [])),
        "seed": config.get("seed", None),
        "ranking_by": config.get("ranking_by", "last"),
        "ranked_timeout": config.get("ranked_timeout", Timeout.RANKED),
        "benchmark_timeout": config.get("benchmark_timeout", Timeout.BENCHMARK),
        "test_timeout": config.get("test_timeout", Timeout.TEST),
        "multi_gpu": config.get("multi_gpu", False),
    }
    if config["lang"] == "py":
        runner = functools.partial(
            run_pytorch_script,
            sources=config["sources"],
            main=config["main"],
            **common_args,
        )
    elif config["lang"] == "cu":
        runner = functools.partial(
            run_cuda_script,
            sources=config["sources"],
            headers=config.get("headers", {}),
            arch=config.get("arch", None),
            defines=config.get("defines", {}),
            include_dirs=config.get("include_dirs", []),
            libraries=config.get("libraries", []),
            flags=CUDA_FLAGS,
            **common_args,
        )
    else:
        raise ValueError(f"Invalid language {config['lang']}")

    results = run_evaluation(runner, config["mode"])
    return FullResult(success=True, error="", runs=results, system=system)
